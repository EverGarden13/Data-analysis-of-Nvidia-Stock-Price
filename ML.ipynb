{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries for data manipulation, visualization, and machine learning (pandas, numpy, matplotlib, seaborn, scikit-learn, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Dataset\n",
    "Load a dataset for machine learning, either from a local file or an online source like scikit-learn datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Dataset\n",
    "\n",
    "# Load dataset from scikit-learn\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['PRICE'] = boston.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('PRICE', axis=1)\n",
    "y = df['PRICE']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Analyze the dataset to understand its structure, check for missing values, and visualize distributions of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Summary statistics of the dataset\n",
    "summary_stats = df.describe()\n",
    "print(\"Summary statistics of the dataset:\\n\", summary_stats)\n",
    "\n",
    "# Visualize the distribution of the target variable (PRICE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['PRICE'], kde=True, bins=30)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of features to visualize relationships\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Clean the data, handle missing values, encode categorical variables, and scale numerical features as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (if any)\n",
    "# Since there are no missing values in the dataset, we can skip this step\n",
    "\n",
    "# Encode categorical variables (if any)\n",
    "# The Boston housing dataset does not contain categorical variables, so we can skip this step\n",
    "\n",
    "# Scale numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled data back to DataFrame for better readability\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# Display the first few rows of the scaled training data\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "Divide the dataset into training and testing sets to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Linear Models\n",
    "Fit linear models such as Linear Regression, Logistic Regression, or Ridge/Lasso Regression to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Linear Models\n",
    "\n",
    "# Import necessary libraries for linear models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the models\n",
    "linear_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the models on the training data\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_linear = linear_reg.predict(X_test_scaled)\n",
    "y_pred_ridge = ridge_reg.predict(X_test_scaled)\n",
    "y_pred_lasso = lasso_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Linear Regression - MSE: {mse_linear:.2f}, R2: {r2_linear:.2f}\")\n",
    "print(f\"Ridge Regression - MSE: {mse_ridge:.2f}, R2: {r2_ridge:.2f}\")\n",
    "print(f\"Lasso Regression - MSE: {mse_lasso:.2f}, R2: {r2_lasso:.2f}\")\n",
    "\n",
    "# Plot the performance of the models\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression']\n",
    "mse_values = [mse_linear, mse_ridge, mse_lasso]\n",
    "r2_values = [r2_linear, r2_ridge, r2_lasso]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MSE values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mse_values, color=['blue', 'green', 'red'])\n",
    "plt.title('Mean Squared Error of Linear Models')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Plot R2 values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, r2_values, color=['blue', 'green', 'red'])\n",
    "plt.title('R2 Score of Linear Models')\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Tree-Based Models\n",
    "Implement decision tree-based models like Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Tree-Based Models\n",
    "\n",
    "# Import necessary libraries for tree-based models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Initialize the models\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the models on the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "gradient_boosting.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "y_pred_gb = gradient_boosting.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Random Forest - MSE: {mse_rf:.2f}, R2: {r2_rf:.2f}\")\n",
    "print(f\"Gradient Boosting - MSE: {mse_gb:.2f}, R2: {r2_gb:.2f}\")\n",
    "\n",
    "# Plot the performance of the models\n",
    "models.extend(['Random Forest', 'Gradient Boosting'])\n",
    "mse_values.extend([mse_rf, mse_gb])\n",
    "r2_values.extend([r2_rf, r2_gb])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MSE values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mse_values, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "plt.title('Mean Squared Error of Models')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Plot R2 values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, r2_values, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "plt.title('R2 Score of Models')\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Neural Network\n",
    "Create and train a simple neural network model using a framework like sklearn's MLPClassifier or a basic Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Implement Neural Network\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMRegressor(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.unsqueeze(1)  # Add sequence dimension\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.unsqueeze(1)  # Add sequence dimension\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    y_pred_mlp = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"LSTM Neural Network - MSE: {mse_mlp:.2f}, R2: {r2_mlp:.2f}\")\n",
    "\n",
    "# Plot the performance of the models including the neural network\n",
    "models.append('LSTM Neural Network')\n",
    "mse_values.append(mse_mlp)\n",
    "r2_values.append(r2_mlp)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MSE values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mse_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('Mean Squared Error of Models')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Plot R2 values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, r2_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('R2 Score of Models')\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance\n",
    "Calculate performance metrics such as accuracy, precision, recall, F1-score, or RMSE for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "\n",
    "# Calculate performance metrics for each model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate and print performance metrics\n",
    "def print_performance_metrics(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "print_performance_metrics(y_test, y_pred_linear, \"Linear Regression\")\n",
    "\n",
    "# Evaluate Ridge Regression\n",
    "print_performance_metrics(y_test, y_pred_ridge, \"Ridge Regression\")\n",
    "\n",
    "# Evaluate Lasso Regression\n",
    "print_performance_metrics(y_test, y_pred_lasso, \"Lasso Regression\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print_performance_metrics(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "print_performance_metrics(y_test, y_pred_gb, \"Gradient Boosting\")\n",
    "\n",
    "# Evaluate Neural Network\n",
    "print_performance_metrics(y_test, y_pred_mlp, \"Neural Network\")\n",
    "\n",
    "# Plot the performance of all models\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Random Forest', 'Gradient Boosting', 'Neural Network']\n",
    "mse_values = [mean_squared_error(y_test, y_pred_linear), mean_squared_error(y_test, y_pred_ridge), mean_squared_error(y_test, y_pred_lasso), mean_squared_error(y_test, y_pred_rf), mean_squared_error(y_test, y_pred_gb), mean_squared_error(y_test, y_pred_mlp)]\n",
    "r2_values = [r2_score(y_test, y_pred_linear), r2_score(y_test, y_pred_ridge), r2_score(y_test, y_pred_lasso), r2_score(y_test, y_pred_rf), r2_score(y_test, y_pred_gb), r2_score(y_test, y_pred_mlp)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MSE values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mse_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('Mean Squared Error of Models')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Plot R2 values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, r2_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('R2 Score of Models')\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Performance Metrics\n",
    "Create visualizations of model performance using bar charts, ROC curves, confusion matrices, or learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Performance Metrics\n",
    "\n",
    "# Import necessary libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\n",
    "\n",
    "# Create a bar chart for Mean Squared Error (MSE) of all models\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mse_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('Mean Squared Error of Models')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Create a bar chart for R2 Score of all models\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, r2_values, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
    "plt.title('R2 Score of Models')\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curves for classification models (if applicable)\n",
    "# Note: The Boston housing dataset is for regression, so ROC curves are not applicable here\n",
    "\n",
    "# Plot confusion matrices for classification models (if applicable)\n",
    "# Note: The Boston housing dataset is for regression, so confusion matrices are not applicable here\n",
    "\n",
    "# Plot learning curves for models (if applicable)\n",
    "# Note: Learning curves are not included in the current implementation\n",
    "\n",
    "# Since the dataset is for regression, we will not plot ROC curves or confusion matrices\n",
    "# Instead, we will focus on the performance metrics already visualized above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models\n",
    "Generate comparison tables and plots to highlight differences in performance metrics across all implemented models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models\n",
    "\n",
    "# Create a DataFrame to store the performance metrics of all models\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Mean Squared Error': mse_values,\n",
    "    'R2 Score': r2_values\n",
    "})\n",
    "\n",
    "# Display the performance metrics table\n",
    "performance_df\n",
    "\n",
    "# Plot the performance metrics for comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Mean Squared Error (MSE) values\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Model', y='Mean Squared Error', data=performance_df, palette='viridis')\n",
    "plt.title('Mean Squared Error of Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "# Plot R2 Score values\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Model', y='R2 Score', data=performance_df, palette='viridis')\n",
    "plt.title('R2 Score of Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('R2 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
